{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to come up with an accuracy measure.\n",
    "\n",
    "During the competition, the final loss will be given using the Pinball loss.\n",
    "\n",
    "![alternative text](pinball_loss.png)\n",
    "\n",
    "So we just need to compare the predicted quantiles to the real raw score of the actual day, since y is always the same.\n",
    "\n",
    "### How do we work with Quantiles?\n",
    "[This](https://timeseriesreasoning.com/contents/introduction-to-the-quantile-regression-model/) and [this](https://www.statsmodels.org/devel/examples/notebooks/generated/quantile_regression.html) were pretty helpful in understanding how this works. It seems as, rather than making a forecast, this Quantile Regression just gives you alternate trajectories of what your data may look like, based on looking at particular quantiles. For example, in the linear world, ordinary least squares will give you a forecast line based on your data's mean, whilte all the other forecast lines will be based on a particular quantile, like in this image:  \n",
    "\n",
    "![alternative text](quant_reg_plot.png)\n",
    "\n",
    "### What does that mean for our code?\n",
    "[smf.quantreg](https://www.statsmodels.org/stable/generated/statsmodels.formula.api.quantreg.html#statsmodels.formula.api.quantreg) lets us estimate a [quantile regression model](https://www.statsmodels.org/dev/generated/statsmodels.regression.quantile_regression.QuantReg.html) using iterative reweighted least squares. Concretely, this means that, given our data, it lets us fit models based on particular quantiles of our data. We can also predict using this model.\n",
    "\n",
    "### What does \"predict\" mean in this case?\n",
    "`smf.quantreg(forumla, data)` just calls `statsmodels.regression.quantile_regression.QuantReg.from_formula`, and this formula handles what is used as the inputs and the target output. The forumla equation of the regression model is in [Patsy](https://patsy.readthedocs.io/en/latest/quickstart.html) syntax, and creates two DesignMatrix objects, the first representing the left-hand side of our formula (y), and the second representing the right-hand side (x1, x2, ..., xn). I believe these are the `endog` (endogenous/response variable) and `exog` (exogenous/explanatory variable(s)), respectively, based on the QuantReg language/documentation. So, when we [predict](https://www.statsmodels.org/dev/generated/statsmodels.regression.quantile_regression.QuantReg.predict.html), it uses the exog of the fitted model by default, meaning it will use the features (x1, ..., xn) of the equation to predict a y', based on the new data we give it. This means that each prediction is based on the particular quantile the model was fit to.\n",
    "\n",
    "### How can we use quantiles in time series forecasts?\n",
    "I am not too familiar with Quantile Regressors but it seems as we will always need one for our setup. I don't know of any other APIs or any machine learning methods that gives us these quantiles but I'm sure they exist. In any case, assuming this model is okay, there are a couple immediate ways that come to mind about how we can use it to do our forecasts:\n",
    "\n",
    "1. We take the quantile-fitted models we get, and use those to predict the quantile for the next days. The input would be, however, all the data for the next day that were used as the exog parameters for the regressor, aka the x values in the formula. The issue here is we obviously do not have access to the SolarDownwardRadiation and WindSpeed for the next day, for example, so we would have to get a predictor for those variables that works well.\n",
    "\n",
    "2. We In this case, the creation of the quantile models is theoretically separate from our predictor, since it is just used to create the data we will predict on. This means if we get a good-enough quantile model (aka if we notice that the model itself doesnt change that much with every new day of data), then we can just keep that QuantReg model fixed and use it to generate the quantiles that will be trained on. In the most basic case, we do not need current values of SolarDownwardRadiation and WindSpeed to make a prediction, since we simply use the quantiles, but if we want to make use of [exogenous data](https://www.sktime.net/en/latest/examples/01_forecasting.html#1.2.3-Forecasters-that-can-make-use-of-exogeneous-data), I think we will need a weather predictor here as well. \n",
    "\n",
    "Fortunately, we can assume having access to solar and wind forecast, because we are able to request this for certain day, via [the api](https://api.rebase.energy/challenges/redoc#tag/Data/operation/get_solar_and_wind_forecast_challenges_data_solar_and_wind_forecast_get).\n",
    "\n",
    "### Open Questions\n",
    "1. Should we be predicting the actual target y somehow, and using this to generate the quantiles, or should we try to forecast the quantiles directly using previous quantiles? Note: In the former case, y should be similar to the 0.5th quantile, which is the conditional median, rather the mean aka y itself. In the latter case, the quantiles are generated by the real y's that were observed in the past.\n",
    "2. The Getting Started notebook has df entries with both `ref_datetime` and `valid_datetime`. ref_datetime is the time from when values were calculated and valid_datetime is the real datetime. But from the \"Forecast scoring\" section of the Getting Started it seems like it is a forecasted value when a row has a ref_datetime entry that is farther in the past than valid_datetime. But ref_datetime only has diff values on 6 hour intervals... and has 96 associated valid_datetimes (2 day forecast at 30 minute intervals, it seems). I also verified that neither all values in the ref_datetime nor valid_datetime columns are unique. Does that mean that the only non-forecasted values are at `modelling_table['ref_datetime'] == modelling_table['valid_datetime']`?? Why did they build the QuantReg model using the predicted values??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/eokoyomon/code/HEFTcom24/src')\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from dotenv import load_dotenv\n",
    "from omegaconf import OmegaConf\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from config import QuantRegConfig\n",
    "from loaders import get_local_data, load_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `pinball_score` function is adapted from the one in the Getting Started jupyter notebook. There they compute the pinball score over the entire modelling_table, which I do not think makes much sense for our case. They generated quantiles for every entry in the dataframe and then calculated the pinball score. But in our case, I think we want to just have the pinball score of the day we are predicting. However, if we keep everything in terms of Dataframes and Series, the code mostly remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinball(y,q,alpha):\n",
    "    return (y-q)*alpha*(y>=q) + (q-y)*(1-alpha)*(y<q)\n",
    "\n",
    "def pinball_score(predicted_quantiles, target):\n",
    "    score = list()\n",
    "    for qu in range(10,100,10):\n",
    "        score.append(pinball(y=target[\"total_generation_MWh\"],\n",
    "            q=predicted_quantiles[f\"q{qu}\"],\n",
    "            alpha=qu/100).mean())\n",
    "    return sum(score)/len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick your target day as a pandas timestamp.\n",
    "TARGET_DAY = pd.to_datetime(np.datetime64(\"2023-09-17 14:30:00\"), utc=True)\n",
    "# Pick the size of the sliding window you want to use for the training data. -1 if you want to use everything earlier than that day.\n",
    "TRAINING_WINDOW = -1\n",
    "# Which model config to use\n",
    "CONFIG = QuantRegConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_target_data(df, target_day, training_window):\n",
    "    # If this is uncommented, values are only on a 6 hour interval. But not sure \n",
    "    # df = df[df['ref_datetime'] == df['valid_datetime']]\n",
    "    df = df.sort_values(by=['ref_datetime', 'valid_datetime'])\n",
    "    target = df.loc[(df['valid_datetime'] >= target_day) & (df['valid_datetime'] < target_day + pd.Timedelta(1, unit=\"day\"))]\n",
    "    training = df[df['valid_datetime'] < target_day]\n",
    "    if training_window != -1:\n",
    "        training = training.tail(training_window)\n",
    "    return training.reset_index(), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs predictors and returns the predicted quantiles and the pinball score.\n",
    "def run_predictor():\n",
    "    load_dotenv()\n",
    "    root = os.getenv(\"root\")\n",
    "    data_dir = os.path.join(root, \"data/\")\n",
    "\n",
    "    inputs, target_data = separate_target_data(get_local_data(data_dir), TARGET_DAY, TRAINING_WINDOW)\n",
    "\n",
    "    config = CONFIG\n",
    "    model = load_module(\"model\", config, inputs)\n",
    "    forecast_models = dict()\n",
    "    predicted_quantiles = pd.DataFrame(index=target_data.index)\n",
    "    predicted_quantiles[\"valid_datetime\"] = target_data[\"valid_datetime\"]\n",
    "\n",
    "    for q in range(10, 100, 10):\n",
    "        print(f\"Starting Predictions for q{q}\")\n",
    "\n",
    "        forecast_models[f\"q{q}\"] = model.fit(quantile=q / 100)\n",
    "        predicted_quantiles[f\"q{q}\"] = forecast_models[f\"q{q}\"].predict(target_data)\n",
    "        predicted_quantiles.loc[predicted_quantiles[f\"q{q}\"] < 0, f\"q{q}\"] = 0\n",
    "\n",
    "    return predicted_quantiles, pinball_score(predicted_quantiles, target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pinball loss score is a bit inaccurate, because both the training and the test data contain forecasts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Predictions for q10\n",
      "Starting Predictions for q20\n",
      "Starting Predictions for q30\n",
      "Starting Predictions for q40\n",
      "Starting Predictions for q50\n",
      "Starting Predictions for q60\n",
      "Starting Predictions for q70\n",
      "Starting Predictions for q80\n",
      "Starting Predictions for q90\n",
      "162.604748036862\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_datetime</th>\n",
       "      <th>q10</th>\n",
       "      <th>q20</th>\n",
       "      <th>q30</th>\n",
       "      <th>q40</th>\n",
       "      <th>q50</th>\n",
       "      <th>q60</th>\n",
       "      <th>q70</th>\n",
       "      <th>q80</th>\n",
       "      <th>q90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1036041</th>\n",
       "      <td>2023-09-17 14:30:00+00:00</td>\n",
       "      <td>38.599000</td>\n",
       "      <td>50.188802</td>\n",
       "      <td>62.571006</td>\n",
       "      <td>68.138713</td>\n",
       "      <td>74.020052</td>\n",
       "      <td>81.045562</td>\n",
       "      <td>87.199232</td>\n",
       "      <td>92.113990</td>\n",
       "      <td>96.853232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036061</th>\n",
       "      <td>2023-09-17 15:00:00+00:00</td>\n",
       "      <td>28.291355</td>\n",
       "      <td>41.385175</td>\n",
       "      <td>53.933486</td>\n",
       "      <td>58.729248</td>\n",
       "      <td>63.783004</td>\n",
       "      <td>69.954173</td>\n",
       "      <td>75.677999</td>\n",
       "      <td>80.266440</td>\n",
       "      <td>84.983800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036081</th>\n",
       "      <td>2023-09-17 15:30:00+00:00</td>\n",
       "      <td>19.676587</td>\n",
       "      <td>30.940787</td>\n",
       "      <td>42.061168</td>\n",
       "      <td>46.156017</td>\n",
       "      <td>50.175643</td>\n",
       "      <td>55.791092</td>\n",
       "      <td>61.118364</td>\n",
       "      <td>65.422524</td>\n",
       "      <td>69.632876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036101</th>\n",
       "      <td>2023-09-17 16:00:00+00:00</td>\n",
       "      <td>11.582763</td>\n",
       "      <td>20.615142</td>\n",
       "      <td>29.847188</td>\n",
       "      <td>33.723472</td>\n",
       "      <td>37.093736</td>\n",
       "      <td>42.342651</td>\n",
       "      <td>47.422437</td>\n",
       "      <td>51.719983</td>\n",
       "      <td>55.631762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036121</th>\n",
       "      <td>2023-09-17 16:30:00+00:00</td>\n",
       "      <td>7.647384</td>\n",
       "      <td>17.298029</td>\n",
       "      <td>26.201234</td>\n",
       "      <td>30.542270</td>\n",
       "      <td>34.163656</td>\n",
       "      <td>39.316506</td>\n",
       "      <td>44.445169</td>\n",
       "      <td>49.073785</td>\n",
       "      <td>53.390635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036912</th>\n",
       "      <td>2023-09-18 12:00:00+00:00</td>\n",
       "      <td>98.191479</td>\n",
       "      <td>125.611869</td>\n",
       "      <td>159.659159</td>\n",
       "      <td>189.498220</td>\n",
       "      <td>212.721767</td>\n",
       "      <td>234.984340</td>\n",
       "      <td>260.491950</td>\n",
       "      <td>278.908350</td>\n",
       "      <td>291.225192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036932</th>\n",
       "      <td>2023-09-18 12:30:00+00:00</td>\n",
       "      <td>77.691363</td>\n",
       "      <td>103.467529</td>\n",
       "      <td>135.862436</td>\n",
       "      <td>163.610165</td>\n",
       "      <td>185.798119</td>\n",
       "      <td>207.302334</td>\n",
       "      <td>232.225319</td>\n",
       "      <td>249.861483</td>\n",
       "      <td>262.089064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036952</th>\n",
       "      <td>2023-09-18 13:00:00+00:00</td>\n",
       "      <td>59.616561</td>\n",
       "      <td>83.825697</td>\n",
       "      <td>114.575218</td>\n",
       "      <td>140.346058</td>\n",
       "      <td>161.327047</td>\n",
       "      <td>181.968290</td>\n",
       "      <td>206.290057</td>\n",
       "      <td>223.173728</td>\n",
       "      <td>235.217669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036972</th>\n",
       "      <td>2023-09-18 13:30:00+00:00</td>\n",
       "      <td>58.929350</td>\n",
       "      <td>84.561939</td>\n",
       "      <td>113.893562</td>\n",
       "      <td>136.407017</td>\n",
       "      <td>155.166491</td>\n",
       "      <td>173.092314</td>\n",
       "      <td>194.110266</td>\n",
       "      <td>208.785184</td>\n",
       "      <td>219.653868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036992</th>\n",
       "      <td>2023-09-18 14:00:00+00:00</td>\n",
       "      <td>58.165990</td>\n",
       "      <td>84.876767</td>\n",
       "      <td>112.612119</td>\n",
       "      <td>131.846804</td>\n",
       "      <td>148.355183</td>\n",
       "      <td>163.610028</td>\n",
       "      <td>181.346652</td>\n",
       "      <td>193.858483</td>\n",
       "      <td>203.660642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   valid_datetime        q10         q20         q30  \\\n",
       "1036041 2023-09-17 14:30:00+00:00  38.599000   50.188802   62.571006   \n",
       "1036061 2023-09-17 15:00:00+00:00  28.291355   41.385175   53.933486   \n",
       "1036081 2023-09-17 15:30:00+00:00  19.676587   30.940787   42.061168   \n",
       "1036101 2023-09-17 16:00:00+00:00  11.582763   20.615142   29.847188   \n",
       "1036121 2023-09-17 16:30:00+00:00   7.647384   17.298029   26.201234   \n",
       "...                           ...        ...         ...         ...   \n",
       "1036912 2023-09-18 12:00:00+00:00  98.191479  125.611869  159.659159   \n",
       "1036932 2023-09-18 12:30:00+00:00  77.691363  103.467529  135.862436   \n",
       "1036952 2023-09-18 13:00:00+00:00  59.616561   83.825697  114.575218   \n",
       "1036972 2023-09-18 13:30:00+00:00  58.929350   84.561939  113.893562   \n",
       "1036992 2023-09-18 14:00:00+00:00  58.165990   84.876767  112.612119   \n",
       "\n",
       "                q40         q50         q60         q70         q80  \\\n",
       "1036041   68.138713   74.020052   81.045562   87.199232   92.113990   \n",
       "1036061   58.729248   63.783004   69.954173   75.677999   80.266440   \n",
       "1036081   46.156017   50.175643   55.791092   61.118364   65.422524   \n",
       "1036101   33.723472   37.093736   42.342651   47.422437   51.719983   \n",
       "1036121   30.542270   34.163656   39.316506   44.445169   49.073785   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "1036912  189.498220  212.721767  234.984340  260.491950  278.908350   \n",
       "1036932  163.610165  185.798119  207.302334  232.225319  249.861483   \n",
       "1036952  140.346058  161.327047  181.968290  206.290057  223.173728   \n",
       "1036972  136.407017  155.166491  173.092314  194.110266  208.785184   \n",
       "1036992  131.846804  148.355183  163.610028  181.346652  193.858483   \n",
       "\n",
       "                q90  \n",
       "1036041   96.853232  \n",
       "1036061   84.983800  \n",
       "1036081   69.632876  \n",
       "1036101   55.631762  \n",
       "1036121   53.390635  \n",
       "...             ...  \n",
       "1036912  291.225192  \n",
       "1036932  262.089064  \n",
       "1036952  235.217669  \n",
       "1036972  219.653868  \n",
       "1036992  203.660642  \n",
       "\n",
       "[400 rows x 10 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles, score = run_predictor()\n",
    "print()\n",
    "print(score)\n",
    "quantiles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HEFTcom24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
